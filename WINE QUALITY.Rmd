---
title: "Wine Quality Analysis Report"
author:
   - Tong SUN (B00771027)
   - Jingjing LIU (B00769592)
   - Lucie BOURY (B00755999)
   - Wanqian LIU (B00782133)
   - Victor KU (B00755459)
   - Shining SHAO (B00771447)
output:
  html_document:
    toc: TRUE
    df_print: paged
  
---

# 1. Introdcution and objective

Wine industry global market was \$378 billion at 2019 and is projected to reach \$434.6 billion by the year 2027 according to a report issued by ReportLinker. Despite of such a large market size, there exists no specific research in defining what is a good wine or what a good wine tastes like, while the most popular evaluation depends mostly on the oenologist’s subjective sensory tests. Meanwhile, the cost of inviting an expert to test the quality and obtaining the quality certification is very high. There isn't a method which can identify the quality of wines quickly and precisely. This data analysis is dedicated to helping actors in the wine industry to find out the relation between good quality and chemical composition and also to better assess the quality of wines they produce, sell or buy through establishing a reliable model using data on market preference and chemical composition of wines. 

The dataset used in this analysis consists of 1609 observations of 11 variables without any missing data and is based on the Portuguese “Vinho Verde”wine. The input variables from physicochemical tests include fixed acidity, volatile, acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol, while the output variable from sensory tests is a quality scoring based on median evaluation from at least 3 wine experts. 
The objective of this step is to explore and visualize the dataset to gain a better understanding of the significant features of the variables. The dataset used in this project is a data sample of red vinho verde wines produced in the north of Portugal.

# 2. Explore the dataset

Let us first log the packages required for the exploratory data analysis.

```{r echo=TRUE, message=FALSE}
## log in the packages
library(PerformanceAnalytics)
library(psych)
library(ggplot2)
library(GGally)
library(gridExtra)
library(tidyverse)
library(lattice)
library(caret)
library(randomForest)
library(party)
library(class)
library(highcharter)
library(e1071)
library(reshape2)
library(fmsb)
library(factoextra)
library(gridExtra)
library(nnet)
library(gridExtra)
library(caret)
library(PerformanceAnalytics)
library(GGally)
library(corrplot)
library(RColorBrewer)
```

## 2.1 Inspection of the dataset

### Loading the dataset
After having set the relevant working directory, we can now load the dataset and do a preliminary inspection of the data. The dataset is available at [this link](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009).


```{r}
wine <- read.csv("C:\\Users\\Administrator\\Desktop\\ESSEC\\wine.csv", header=T, stringsAsFactors = F)
View(wine)
str(wine)
sum(is.na(wine))
```

We can see that the dataset contains 1609 observations of 12 variables, 11 input variables from physiochemical tests and 1 output variable from sensory tests: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol and quality. Quality is a score between 0 and 10 based on median evaluations of a wine by at least 3 wine experts.

The set has no missing value.

### Standard descriptive statistics

```{r}
wine_stats <- as.data.frame(apply(wine,2,summary))
wine_stats <- round(wine_stats,digits=2)
wine_stats
```

```{r}
describe(wine)
```

The tables give us some standard descriptive statistics of our variables.


## 2.2 Visualization of the variables

### Distribution of "quality"

```{r}
distribution <- ggplot(wine,aes(x=quality)) + 
  geom_bar(fill="darkred") + 
  labs(x="Quality Score", y="Count", title="Distribution of 'Quality' feature") + 
  theme_classic() +
  theme(axis.title = element_text(size=14),axis.text = element_text(size=14),plot.title=element_text(size=16,face="bold",hjust = 0.5))
distribution

```

The distribution plot of the output variable "quality" displays a normal distribution: wine scores range from 3 to 8 with an over-representation of 5- and 6-rated wines.

### Correlation Matrix

```{r}
correlation_values <- ggcorr(wine[,c(2:13)], name = "corr", label = TRUE)+
  theme(legend.position="right")+
  labs(title="Correlation Matrix of Input Variables")+
  theme (axis.text.y = element_text(size = 14),
         plot.title=element_text(face='bold',color='black',hjust=0.5,size=16))

print(correlation_values)

```

The matrix gives us a clear depiction of significant correlation, or lack thereof, between variables.

Significant correlation with "quality" : 

Alcohol and sulphate have a positive correlation, whereas citric acid and volatile acidity and negatively correlated with quality. 

Residual sugar is uncorrelated with quality.


Correlation among input variables: 

citric.acid vs fixed.acidity (++)

density vs  fixed.acidity (++)

free vs total sulfur dioxide (++)

citric.acid vs volatile acidity (--)

pH vs total acidity (--)




# 3. Feature engineering

## 3.1 Correlation method
We firstly proceed to a general visualization of the variables using several methods to check the correlations between all the features more precisely.

```{r}
chart.Correlation(wine[,c(1:12)],histogram=TRUE, col="grey10", pch=1, main="Wine")

```

```{r message=FALSE}

pearson_correlation_plots <- pairs.panels(wine[,c(1:12)], method="pearson",
             hist.col = "#1fbbfa", density=TRUE, ellipses=TRUE, show.points = TRUE,
             pch=1, lm=TRUE, cex.cor=1, smoother=F, stars = T, main="Pearson Correlation Plots")

```

### Categorization of quality

The creation of categories of qualities allows us to prepare the dataset for classification modelling as well as getting a clearer visualization of key features of the variables.

```{r}
wine$quality <- as.factor(wine$quality)
wine$quality_cat <- ""
wine$quality_cat[wine$quality=="3"] <- "inferior"
wine$quality_cat[wine$quality=="4"|wine$quality=="5"|wine$quality=="6"] <- "qualified"
wine$quality_cat[wine$quality=="7"|wine$quality=="8"] <- "amazing"

```


Score ≤ 3 (green): “Inferior”

Score ∈ [4;6] (blue): “Qualified”

Score ≥ 7 (red): “Amazing”

```{r}

```
### Categorized pair plots of variables
```{r message=FALSE}
relation <- ggpairs(wine[,c(2:12,14)], aes(color=quality_cat, alpha=0.3), lower=list(continuous="smooth"))+ theme_bw()+
  labs(title="Visualization of relations between variables")+
  theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
print(relation)
```

The generalized pair plots using ggpairs() give out 3 kinds of analysis:
correlation coefficients (upper triangle)
distribution plots (diagonal)
scatter plots (lower triangle)

### Conclusions
Before we establish the regression and classification models, we should make sure that the features we will use are all exogenous features, otherwise there will be spurious regression and the model is not unbiased and reliable.

Based on the plots we generated above, we found that the fixed.acidity has strong correlations with other features. The residual.sugar and the free.sulfur.dioxide have no relationship with the quality. So we exclude these 3 features and choose other 8 features as our key features to establish the forecast models.

## 3.2 PCA analysis
Some variables are linearly correlated. This leads to unnecessary high dimension and maybe to insignificant variables in the regression model, so we used PCA analysis and tried to decrease the dimensions of our data. 

### Components selection
```{r echo=TRUE}
set.seed(300)
df <- read.csv("C:\\Users\\Administrator\\Desktop\\ESSEC\\wine.csv", header=T, stringsAsFactors = F)
df$id <- NULL
x <- df[1:11]
y_num <- df$quality
y <- factor(df$quality)
pca <- prcomp(x,center=TRUE, scale = TRUE)
summary(pca)
```

```{r echo=TRUE}
vars <- apply(pca$x, 2, var)  
props <- vars / sum(vars)
a= data.frame(cumsum(props))
a$component <- row.names(a)

ggplot(data=a,aes(y=cumsum.props.,x=reorder(component, cumsum.props.)))+ 
  geom_bar(stat='identity',fill="darkred") +
  geom_point() + geom_text(vjust=-0.5,aes(label=paste0(round(cumsum.props.*100,1),"%")))+ 
  geom_hline(yintercept=0.947,linetype = "dashed",size=1) + 
  xlab("Principal Components")+ylab("Cumulative Proportion of Variance") +
  theme_bw()
```

```{r echo=TRUE}
fviz_eig(pca, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "darkred", barcolor="darkred",linecolor = "black", ncp=10)+
labs(title = " Variances - PCA",
         x = "Principal Components", y = "% of variances")
```
    
With 8 components we can explain 94.7% of the dataset's variance. So we choose to only keep 8 components in the PCA.

### Contributions of variables : 
```{r}
pca_var = get_pca_var(pca)
corrplot(pca_var$cos2, is.corr=FALSE) 
```

The plot above shows the cos2 of each variable with respect to each principal component. The cos2 represents the correlation of each variable with the principal components. We can see that Dim.1 depends highly on fixed.acidity, citri.acid and pH. It might be a component that somewhat represents the acidity of the wine. Dim.2 is more about sulfure dioxide level in wine and Dim.3 about alcohol and volatile.acidity. 

```{r}
fviz_pca_var(pca,axes=c(1,3),col.var = "cos2",gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

This circle is called a correlation circle and shows the cos2 for Dim1 and Dim3.

### Individuals in the PCA 

```{r}
fviz_pca_ind (pca,axes = c(1,3),geom = "point",col.ind = y,repel=TRUE,addEllipses=TRUE, ellipse.level=0.95,pointsize=0,ellipse.alpha=0.3)
```

We have plotted all observations according to the value they have in Dim1(x) and Dim3(y). We colored the points according to the quality level of the each observation. The ellipses are 95% confidence intervals of each quality distribution with respect to Dim1 and Dim3.  
In this graph we can see that :  

- Quality 3 doesn't seem to be dependent of Dim1 but has positive values in Dim3
- Quality 8 seems to have negative values in Dim3
- All ellipses seem to be flattened with respect to Dim1 
- Lower qualities (3-4) decrease in Dim3 while increasing in Dim1 
- Higher quality (8) increases simultaneously in Dim1 and Dim3. 

# 4. Regression Models 

Since output values ranges between 3 and 8, they can be at first considered as a continuous grading. Thus, we can first try regression models. The ideas is use different models to make continuous prediction and then round to the closest integer value.  

In the regressions, the dependent variable is quality and the independent variables are the 8 principal components we kept from the PCA.
```{r}
x_new <- data.frame(pca$x[,1:8])
df_new <- x_new
df$quality <- y_num
df_new$quality <- y_num
nrows <- NROW(df_new)   
index <- sample(1:nrows, 0.7 * nrows) 
test_new <- df_new[-index,]
```

## 4.1 Classical linear regression model

We split the dataset in a training set on which we set the model and a testing on which we will test it. Then we process the linear regression

```{r}
train_new <- df_new[index,]
mod_lm_1 <- lm(quality ~ .,train_new)
coef_mod_lm <- data.frame(mod_lm_1$coefficients[2:9])
coef_mod_lm$Variables <- row.names(coef_mod_lm)
colnames(coef_mod_lm) <- c("Coefficients","Variables")
ggplot(data=coef_mod_lm)+geom_bar(aes(x=Variables,y=Coefficients),stat="identity",fill="darkred")+theme_light()
```
```{r}
summary(mod_lm_1)
```

We can see that almost all components are signicant at 0.05 significance level. 
  
```{r}
pre_lm_1 <- predict(mod_lm_1,test_new[1:9])
pre_lm_1 <- factor(round(pre_lm_1, 0),levels = c("3","4","5","6","7","8"))
cm_lm_1 <- confusionMatrix(pre_lm_1, factor(test_new$quality))
cm_lm_1
```
  
  
The accuracy is 59.21% which is not very good. Looking at the confusion matrix we can see that the model predicts almost every wine to be quality 5 or 6. Extreme qualities (3-4-8) have a sensitivity of 0. Thus, the model is not acceptable since it neither detects bad wines or good wines.
  
## 4.2 GLM

```{r,fig.height=4,fig.width=3}
ggplot(data=df)+ geom_histogram(aes(x=quality,y=..density..),fill="darkred",binwidth = 0.5)+theme_bw() +
  theme(panel.border = element_blank(),plot.title = element_text(hjust = 0.5,size=11)) +labs(x="quality")+ggtitle("Distribution of Quality in the dataset")
```

The dataset seems to be Poisson distributed, we will try to use a GLM with Poisson distribution : 

```{r message=TRUE, warning=FALSE}
glm_poisson <-  glm(quality~.,data=train_new,family=poisson)
pre_poisson <- factor(round(exp(predict(glm_poisson,test_new[1:9])),0))
pre_poisson <- unname(pre_poisson)
cm_poisson <- confusionMatrix(pre_poisson, factor(test_new$quality))
cm_poisson
```
  
The model gives an accuracy of 59.63% which is slightly better than the CLRM but still has 0 sensitivity for extreme qualities.  
  
The model is not acceptable either. 
  
## 4.3 Conclusion
```{r,message=FALSE}
sen_lm <- unname( cm_lm_1$byClass[,1])
sen_poisson <- unname( cm_poisson$byClass[,1])
sensitivity <- matrix(data=sen_lm,ncol=2,nrow=6,byrow = FALSE)
sensitivity[,2] <- sen_poisson
sensitivity <- data.frame(sensitivity)
colnames(sensitivity) <- c("Linear","Poisson")
sensitivity$Quality=c(3,4,5,6,7,8)
sensitivity <- gather(sensitivity,"Model","Sensitivity",-Quality)
```

```{r}
ggplot(data=sensitivity, aes(x=Quality,y=Sensitivity,color=Model))+ geom_line()+theme_bw() + ggtitle("Sensitivities depending of model choice")
```

```{r,fig.width=20,fig.height=8}
heat_lm <- ggplot(data = data.frame(cm_lm_1$table), aes(x=Reference, y=Prediction)) +
  geom_tile(aes(fill=Freq)) +scale_fill_distiller(palette = "YlOrRd")+
  geom_text(aes(label = Freq))+ ggtitle("CM Linea Model")
heat_poisson <- ggplot(data = data.frame(cm_poisson$table), aes(x=Reference, y=Prediction)) +
  geom_tile(aes(fill=Freq)) +scale_fill_distiller(palette = "YlOrRd")+
  geom_text(aes(label = Freq))+ ggtitle("CM GLM POISSON")
grid.arrange(heat_lm,heat_poisson,ncol=2,nrow=1)
```

Both regression models show poor results. We should consider another point of view with classification models. 

# 5. Classification Models

In this part, we will use 5 different machine learning algorithms to train our dataset, and make classifications and predictions. The models we used are Random Forest, SVM, SVM-Tune, C-tree and KNN-Tune.

The target feature is quality and we defined 3 states for this feature which are 'inferior'(<=3), 'qualified'(4-6) and 'amazing'(>=7) based on the common evaluation standard for wine quality.

**Note**: SVM-Tune and KNN-Tune are based on standard SVM and KNN models, but we select the optimized hyperparameters for these 2 models.

## 5.1 Data Cleaning

Because our dataset has no null value, we just reshaped the dataset and deleted the features we don't need as our explanation in feature engineering part.

```{r datacleaning, echo=TRUE}
wine <- read.csv("C:\\Users\\Administrator\\Desktop\\ESSEC\\wine.csv", header=T, stringsAsFactors = F)
num_row<-NROW(wine)

evaluation <- matrix(nrow=num_row,ncol=1) 
colnames(evaluation) <- c("evaluation")

for (i in seq(1,num_row,1)){
  if(wine$quality[i]<=3){
    evaluation[i]<-"inferior"
  }
  else if(wine$quality[i]>= 4 & wine$quality[i] <= 6){
    evaluation[i]<-"qualified"
  }
  else {
    evaluation[i] <- 'amazing'
  }
}

wine<-cbind.data.frame(evaluation,wine)
wine<- wine[,!grepl("quality",names(wine))]

wine$evaluation <- factor(wine$evaluation)
wine_re <- wine[, c(-2, -3,  -6, -8)]  ## feature selection

head(wine,5)

```

### Train/Test split

We divided dataset into train set(70%) and test set(30%) to make the classification and prediction.
```{r echo=TRUE}
nrows <- NROW(wine_re)
set.seed(300)                           ## fix random value
index <- sample(1:nrows, 0.7 * nrows)   ## shuffle and divide

train <- wine_re[index,]                   
test <- wine_re[-index,]

```
check the proportional of train and test set

```{r echo=TRUE}

prop.table(table(train$evaluation))
prop.table(table(test$evaluation))

```

## 5.2 Apply machine learning algotrithms to dataset

### Random Forest

```{r echo=TRUE}
learn_rf <- randomForest(evaluation~., data=train, ntree=500, proximity=T, importance=T)
pre_rf   <- predict(learn_rf, test[,-1])
cm_rf    <- confusionMatrix(pre_rf, test$evaluation)
cm_rf
```
The accuracy of random forest model is 90.89%

### CTree

```{r echo=TRUE}
learn_ct <- ctree(evaluation~., data=train, controls=ctree_control(maxdepth=2))
pre_ct   <- predict(learn_ct, test[,-1])
cm_ct    <- confusionMatrix(pre_ct, test$evaluation)
cm_ct
```

The accuracy for Ctree is 88.20%

### KNN-Tune

```{r echo=TRUE}
acc_test <- numeric() 

for(i in 1:30){
  predict <- knn(train=train[,-1], test=test[,-1], cl=train[,1], k=i, prob=T)
  acc_test <- c(acc_test,mean(predict==test[,1]))
}

acc <- data.frame(k= seq(1,30), cnt = acc_test)

opt_k <- subset(acc, cnt==max(cnt))[1,]
sub <- paste("Optimal number of k is", opt_k$k, "(accuracy :", opt_k$cnt,") in KNN")

pre_knn <- knn(train = train[,-1], test = test[,-1], cl = train[,1], k=opt_k$k, prob=T)
cm_knn  <- confusionMatrix(pre_knn, test$evaluation)
cm_knn
```

```{r echo=TRUE}
hchart(acc, 'line', hcaes(k, cnt)) %>%
  hc_title(text = "Accuracy With Varying K (KNN)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Neighbors(k)")) %>%
  hc_yAxis(title = list(text = "Accuracy"))
```
The optimized hyperparameter for KNN model is 24.
The accuracy of KNN-Tune model is 84.89%.

### svm

```{r echo=TRUE}
learn_svm <- svm(evaluation~., data=train)
pre_svm <- predict(learn_svm, test[,-1])
cm_svm <- confusionMatrix(pre_svm, test$evaluation)
cm_svm
```

The accuracy of SVM is 88.41%.

### SVM-Tune

```{r echo=TRUE}
gamma <- seq(0,0.1,0.005)
cost <- 2^(0:5)
parms <- expand.grid(cost=cost, gamma=gamma)    

acc_test <- numeric()
accuracy1 <- NULL; accuracy2 <- NULL

for(i in 1:NROW(parms)){        
  learn_svm <- svm(evaluation~., data=train, gamma=parms$gamma[i], cost=parms$cost[i])
  pre_svm <- predict(learn_svm, test[,-1])
  accuracy1 <- confusionMatrix(pre_svm, test$evaluation)
  accuracy2[i] <- accuracy1$overall[1]
}

acc <- data.frame(p= seq(1,NROW(parms)), cnt = accuracy2)

opt_p <- subset(acc, cnt==max(cnt))[1,]
sub <- paste("Optimal number of parameter is", opt_p$p, "(accuracy :", opt_p$cnt,") in SVM")



learn_imp_svm <- svm(evaluation~., data=train, cost=parms$cost[opt_p$p], gamma=parms$gamma[opt_p$p])
pre_imp_svm <- predict(learn_imp_svm, test[,-1])
cm_imp_svm <- confusionMatrix(pre_imp_svm, test$evaluation)
cm_imp_svm
```

```{r echo=TRUE}
hchart(acc, 'line', hcaes(p, cnt)) %>%
  hc_title(text = "Accuracy With Varying Parameters (SVM)") %>%
  hc_subtitle(text = sub) %>%
  hc_add_theme(hc_theme_google()) %>%
  hc_xAxis(title = list(text = "Number of Parameters")) %>%
  hc_yAxis(title = list(text = "Accuracy"))
```

The optimal hyperparameter for SVM model is 126.
The accuracy of SVM-Tune is 89.44%.

## 5.3 Model performance analysis

```{r echo=TRUE}
col <- c("#EEA2AD", "#9BCD98")
par(mfcol=c(3,5), oma =c(0,3,3,0))

fourfoldplot(cm_rf$table[c(1,2), c(1,2)], color = col, conf.level = 0, margin = 1,)
mtext(paste("RandomForest (",round(cm_rf$overall[1]*100),"%)",sep=""), line = 3, cex = 0.8 )
mtext('amazing vs inferior', side = 2, line = 4, cex = 0.8)
fourfoldplot(cm_rf$table[c(2,3), c(2,3)], color = col, conf.level = 0, margin = 1)
mtext('inferior vs qualified', side = 2, line = 4, cex = 0.8)
fourfoldplot(cm_rf$table[c(1,3), c(1,3)], color = col, conf.level = 0, margin = 1) 
mtext('amazing vs qualified', side = 2, line = 4, cex = 0.8)

fourfoldplot(cm_imp_svm$table[c(1,2), c(1,2)], color = col, conf.level = 0, margin = 1) 
mtext(paste("SVM-Tune (",round(cm_imp_svm$overall[1]*100),"%)",sep=""), line = 3, cex = 0.8)
fourfoldplot(cm_imp_svm$table[c(2,3), c(2,3)], color = col, conf.level = 0, margin = 1) 
fourfoldplot(cm_imp_svm$table[c(1,3), c(1,3)], color = col, conf.level = 0, margin = 1) 

fourfoldplot(cm_svm$table[c(1,2), c(1,2)], color = col, conf.level = 0, margin = 1) 
mtext(paste("SVM (",round(cm_svm$overall[1]*100),"%)",sep=""), line = 3, cex = 0.8)
fourfoldplot(cm_svm$table[c(2,3), c(2,3)], color = col, conf.level = 0, margin = 1) 
fourfoldplot(cm_svm$table[c(1,3), c(1,3)], color = col, conf.level = 0, margin = 1) 

fourfoldplot(cm_ct$table[c(1,2), c(1,2)], color = col, conf.level = 0, margin = 1) 
mtext(paste("CTree (",round(cm_ct$overall[1]*100),"%)",sep=""), line = 3, cex = 0.8)
fourfoldplot(cm_ct$table[c(2,3), c(2,3)], color = col, conf.level = 0, margin = 1) 
fourfoldplot(cm_ct$table[c(1,3), c(1,3)], color = col, conf.level = 0, margin = 1) 

fourfoldplot(cm_knn$table[c(1,2), c(1,2)], color = col, conf.level = 0, margin = 1)
mtext(paste("KNN-Tune (",round(cm_knn$overall[1]*100),"%)",sep=""), line = 3, cex = 0.8)
fourfoldplot(cm_knn$table[c(2,3), c(2,3)], color = col, conf.level = 0, margin = 1) 
fourfoldplot(cm_knn$table[c(1,3), c(1,3)], color = col, conf.level = 0, margin = 1)
```

## 5.4 Conclusions
From the plot above, we can find several conclusions.

1. When we applied 5 classification algorithms to test set, the random forest model has the highest accuracy with approximately 91%.

2. All 5 models can differentiate the amazing wine and the inferior wine very well.

3. Except for random forest model and SVM-Tune model, other 3 models cannot differentiate the qualified wine and inferior wine.

For the final model selection, we first exclude the SVM model, Ctree model and KNN-Tune model. Because they have a serious problem - upward forecast, such as the model predicts an inferior wine as a qualified wine. This problem is strictly unacceptable. The wine producers will suffer a huge failure, if they bring a inferior wine to the market. Meanwhile, it will harm our company's reputation and reliability because we give a wrong prediction to the wine producers. Between random forest model and SVM-Tune model, the former is better due to its higher accuracy.

Therefore our final classification model for this project is random forest model.

However, this model has a drawback as well. It cannot distinguish the amazing and qualified wine. More than half amazing wines are predicted as qualified wines, but this is acceptable and less harmful for 2 reasons.
1. Our dataset has only 1000+ observations and about 100 observations of amazing wine , so the model may not be trained enough to differentiate these 2 categories. 
2. The boundary between amazing wine and qualified wine is very ambiguous and subjective and the wine's grades  given by 3 wine experts may have some biases, resulting in this drawback. For the worst cases, if the wine is just qualified, but the wine producers think their wines are amazing based on our model and bring them to the market, they won't suffer a huge failure, because most customers cannot differentiate the amazing and qualified wine as well.

# 6. Diagnosis report

## 6.1 Generate diagnosis template
We position ourselves as a wine consulting company, so we should have the ability to predict the quality of many different wines at one time. The following codes give us this ability.

```{r echo=TRUE}
quality_predict = function(df){
  df$evaluation <- NULL
  learn_rf <- randomForest(evaluation~., data=train, ntree=500, proximity=T, importance=T)
  pre_rf   <- predict(learn_rf, df[,c(-1, -2, -5, -7)])
  pre_rf_str <- as.character(pre_rf)
  return(paste('Wine ID:', df$id, "Prediction: ", pre_rf_str, spe = ''))
}

quality_predict_output <- function(df){
  evaluation <- df$evaluation
  df <- df[, -1]
  learn_rf <- randomForest(evaluation~., data=train, ntree=500, proximity=T, importance=T)
  pre_rf   <- predict(learn_rf, df[,c(-1, -2, -5, -7)])
  pre_rf_str <- as.character(pre_rf)
  output_table <- data.frame(id = df$id, origin_quality = evaluation, predict_quality = pre_rf_str) %>% mutate(evaluation = ifelse(origin_quality == predict_quality,'Correct', 'Wrong'))
  return(output_table)
}

test_new <- wine[-index,]
output_table <- quality_predict_output(test_new)
head(output_table,10)
```

## 6.2 Generate diagnosis report
As a consulting company, we cannot assume all our clients know about the statistics and machine learning, so we try to generate a diagnosis report to explain our prediction results and convince our clients. We use Wine No.115 as an example.

```{r echo=TRUE}
diagnosis_report <- function(new,data) {
  title <- "Wine quality diagnosis report"
  subtitle <- quality_predict(new)
  
  m_train <- data[, c(-2,-3,-6,-8)]
  m_train <- melt(data = m_train, id.vars = 'evaluation')
  m_new <- melt(new[, c(-2,-3,-6,-8)], id.vars = 'evaluation' )

  report <- ggplot(m_train, aes(x=value,color=evaluation, fill=evaluation))+
    geom_histogram(aes(y=..density..), alpha=0.5, position="identity", bins=50)+
    geom_density(alpha=.2)+
    scale_color_manual(values=c("#15c3c9", "#ffe61b","#f87b72"))+
    scale_fill_manual(values=c("#61d4d6", "#ffec54","#f5a7a1"))+
    geom_vline(data= m_new, aes(xintercept=value), 
               color='green', size=1.5)+
    geom_label(data=m_new, aes(x=Inf, y=Inf, label=round(value,3)), nudge_y=2,  
               vjust = "top", hjust = "right", fill="white", color="black")+
    labs(title=title, subtitle=subtitle)+
    theme(plot.title = element_text(face='bold', colour='black', hjust=0.5, size=15))+
    theme(plot.subtitle=element_text(lineheight=0.8, hjust=0.5, size=12))+
    facet_wrap(~variable, scales="free", ncol=4)

  report

}

A <- wine[115, ]
diagnosis_report(A, wine)
```

This report show the distributions of 3 categories for each key features and the green vertical line is the values of key features for a particular wine. From the diagnosis report above, we can find that all the values of key features of wine No.115 is close to the mean of inferior wine. That's why wine No.115 is predicted as 'inferior'. This diagnosis report may not explain how the forecast result is generated from the machine learning perspectives, but it's very easy for our clients to understand.

## 6.3 Radar chart for improvement
After showing the diagnosis reports to our clients, we will give them a radar chart to suggest how they can improve their wines.

```{r echo = TRUE}
radar_plot <- function(selected_wine, data){
  normalize <- function(x){
    normalization <- (x - min(x)) / (max(x) - min(x))
    return (normalization)
  }

  qualified_set <- subset(data, evaluation == 'qualified', select = c(-1,-2,-3,-6,-8))
  qualified_set_normalized <- as.data.frame(lapply(qualified_set, normalize))
  qualified_normalized_mean <- colMeans(qualified_set_normalized)

  p_new <- (selected_wine[,c(-1,-2,-3,-6,-8)] - apply(qualified_set,2,min)) / (apply(qualified_set, 2, max) - apply(qualified_set, 2, min))
  radar_data <- rbind(c(1.5,1,1,1,1,1,1,1), rep(0,8), t(qualified_normalized_mean), p_new)
  rownames(radar_data) <- c('max','min','qualified',  'selected')
  
  colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) )
  colors_in=c(rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4))

  radarchart(radar_data, axistype=1, pcol=colors_border , pfcol=colors_in , plwd = 4, plty=1,
                        cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,1.5,5),cglwd=0.8,
                        vlcex=0.8, title = 'The radar chart for improvement')
  legend(x=1.5, y=1, legend = rownames(radar_data[-1:-2,]), bty = "n", pch=20 , 
         col=c(rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4)), text.col = "grey", cex=1.2, pt.cex=3)
  mtext(side = 3, line = -0.3, at = 0, cex = 0.9, paste(quality_predict(A)))
  
}

radar_plot(A, wine)
```

The blue area is the means of key features of qualified wines and the red area is the values of key features of selected wine which is planned to improve. For wine No.115 the volatile.acidity, citric.acid, total.sulfur.dioxide and pH is far from the means of qualified wine, but other features are very close to the means of qualified wines. So the producer of wine No.115 should try to balance the potential of hydrogen in order to improve the quality in his future production process.

Our suggestions here may be a little ambiguous, this is because the key features of our dataset is only 8 and this radar chart is just an example. The suggestions will be more concrete with the further development of our model and more explorations on features to include more features which has a significant impact on the quality of wines.


# 7. Conclusions and future work
We explored the wine quality dataset and tried to establish the classification models to predict the quality of the wine, we find:

1. Compared with logistic regression and other classification models, the random forest model has the best performance and doesn't have the upward forecast problem between inferior wines and qualified wines. This model is our final model for this project. 

2. The random forest model cannot differentiate the amazing wine and qualified wine very well. But based on our analysis, this is not a very serious problem. And at least our model can quickly and precisely differentiate the qualified wine and inferior wine, which is our may concern.

3. By our model, we can give some suggestions to the wine producers on how to improve the quality of their wine in their future producing process.

4. Currently, the quality of wines mainly depends on the judgment of the wine experts. However, the cost of inviting an wine expert and obtaining the quality certification is very high. Our classification model can quickly and precisely predict the wine quality and then give specific suggestions on how to improve the quality. Especially, it has strong ability to differentiate the inferior wines, which is the main problem that plagues the wine producers.Therefore, our project has a huge business potential. 

Our future work will mainly be focused on how to improve our final model and tackle its drawbacks:

1. Feature engineering: We will try to find and select more key features which are omitted in our current analysis.

2. Expand the dataset to improve the accuracy of learning.

3. Develop some optimized algorithms to improve the efficiency of learning.

